{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_ = requests.get('http://tolstoy.ru/creativity/90-volume-collection-of-the-works/').text\n",
    "hrefs = re.findall('<li><a href=\\\"(/creativity/[^\"]+)\\\">(?:[^<>]*?)</a></li>', html_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://tolstoy.ru'\n",
    "for i, href in enumerate(hrefs):\n",
    "    if i < 90:\n",
    "        continue\n",
    "    html_ = requests.get(f'{base_url}{href}').text\n",
    "    fb2 = re.findall('<a href=\"(/upload.*?\\.fb2)\"', html_)\n",
    "    if fb2:\n",
    "        fb2 = fb2[0]\n",
    "    else:\n",
    "        fb2 = None\n",
    "        epub = re.findall('<a href=\"(/upload.*?\\.epub)\"', html_)[0]\n",
    "    if fb2 is not None:\n",
    "        response = requests.get(f'{base_url}{fb2}')\n",
    "        with open(f'tom_{i + 1}.fb2', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    else:\n",
    "        response = requests.get(f'{base_url}{epub}')\n",
    "        with open(f'tom_{i + 1}.epub', 'wb') as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''\n",
    "for tom in range(1, 91):\n",
    "    with open(os.path.join('true_revised', f'revised_tom_{tom}.txt'), 'r', encoding='utf-8') as f:\n",
    "        text += f.read()\n",
    "with open('all_revised_toms.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for tom in range(1, 91):\n",
    "    with open(os.path.join('true_revised', f'revised_tom_{tom}.txt'), 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    for symbol in ['X', 'V', 'I', '\\.', '\\[', '\\*', 'глава', 'Глава', 'ГЛАВА', '\\—\\—', '_']:\n",
    "        text = re.sub(fr'\\n{symbol}.*?(?=\\n)', '', text)\n",
    "    for symbol in ['̀', '<', '>', '\\[', '\\]', '\\d+(?=\\n)', '[.!?,»):;«(—-’́\\'\\\" ]*[^\\s\\dа-яА-ЯёЁ.!?,»):;«(—-’́\\\"]+(?=[.!?,»):;«(—-’ \\'\\\"́]*)']:\n",
    "        text = re.sub(symbol, ' ', text)\n",
    "    text = re.sub('́', ' ', text)\n",
    "    text = re.sub('̀', ' ', text)\n",
    "    text = re.sub('(?:\\n)\\s+', '', text)\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('\\n +', '\\n', text)\n",
    "    text = re.sub(' +\\n', '\\n', text)\n",
    "    text = re.sub('\\n[^\\n]*?[IiЪъѢѣѲѳѴѵ][^\\n]*?(?=\\n|$)', '', text)\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    text = re.sub('\\n\\d+.*?(?=\\n)', '', text)\n",
    "    with open(os.path.join('true_revised', f'revised_tom_{tom}.txt'), 'w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_toms.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    for symbol in ['X', 'V', 'I', '\\.', '\\[', '\\*', 'глава', 'Глава', 'ГЛАВА', '\\—\\—', '_']:\n",
    "        text = re.sub(fr'\\n{symbol}.*?(?=\\n)', '', text)\n",
    "    for symbol in ['̀', '<', '>', '\\[', '\\]', '[.!?,»):;«(—-’́\\'\" ]+[a-zèéùêüöàôA-ZÈç]+[.!?,»):;«(—-’ \\'\"́]+', '\\d+(?=\\n)']:\n",
    "        text = re.sub(symbol, ' ', text)\n",
    "    text = re.sub('́', ' ', text)\n",
    "    text = re.sub('̀', ' ', text)\n",
    "    text = re.sub('(?:\\n)\\s+', '', text)\n",
    "    text = re.sub('\\n+', '\\n', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = re.sub('\\n +', '\\n', text)\n",
    "    text = re.sub(' +\\n', '\\n', text)\n",
    "    text = re.sub('\\n.*?[IiЪъѢѣѲѳѴѵ].*?(?=\\n)', '', text)\n",
    "\n",
    "with open('all_toms_cleaned_out.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('all_toms_cleaned_out.txt', 'r', encoding='utf-8') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "with open('all_toms_cleaned_out_modern.txt', 'w', encoding='utf-8') as f:\n",
    "    text = '\\n'.join([line for line in text.split('\\n') if not ])\n",
    "#     text = re.sub('\\n.*?[IiЪъѢѣѲѳѴѵ].*?(?=\\n)', '', text)\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.stat('all_toms_cleaned_out_modern.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
