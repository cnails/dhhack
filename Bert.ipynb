{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKn7MbzfkcDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9f_St2Xki88",
        "colab_type": "code",
        "outputId": "8519ece0-9cfb-4226-9548-628bf877ebb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl5Kkti-6qxj",
        "colab_type": "text"
      },
      "source": [
        "Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtycXG7DjBgZ",
        "colab_type": "code",
        "outputId": "a1f5b2f1-6d58-47c2-f854-f819db01c17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "import keras\n",
        "!pip install keras_bert\n",
        "from keras_bert import load_vocabulary, load_trained_model_from_checkpoint, Tokenizer, get_checkpoint_paths\n",
        "from keras_bert.layers import MaskedGlobalMaxPool1D\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/df/fe/bf46de1ef9d1395cd735d8df5402f5d837ef82cfd348a252ad8f32feeaef/keras-bert-0.80.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.17.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.2.5)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/57/496b1eab888171b0801a0a44d3245a7874b8d1cc04c1fbfdbb5e3327fc7a/keras-transformer-0.31.0.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.3.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.80.0-cp36-none-any.whl size=37923 sha256=9ab2dc70ad12cf3394116dc75aa19eb1c6b984b8a090f3aefb8665eba33b8d0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/dc/87/3260cb91f3aa32c0f85c5375429a30c8fd988bbb48f5ee21b0\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.31.0-cp36-none-any.whl size=13385 sha256=ccc8c1cfe1cb935e406f48a21489c9a246a7a1b7d53f2f1ada1d2d69a31a6629\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/c5/9a/5a5130240be614a7a6fa786765d7692ae97f82601e2161bb56\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=c35ca803d369a8f48c60ffd5235057a9a22512de02f8ea5762b85e4c32b24ca8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=ed7ac3d68b280d04797a04d48094ae33a59ac3367f12f10c31cbb0cf4e32b273\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=aeff489550e3a4a2e38ddb2c6f2d9da4207b826f0150ec979660717d7229a453\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=9897678a9f1b73b83ec06ca5942f699e4a064a25318705c3d7e471dd5401a873\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=058320b628f529582f44146325b4b4f81154a90f2218a880a76c7b93614e229e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=90db0c447ceb1497977e961ec1dff2fe700ca7f69a9c73ab757cc595bb4ae226\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.80.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.31.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjXV0HjLjBe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_path = '/content/drive/My Drive/bert'\n",
        "paths = get_checkpoint_paths(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jggBnvEajBb2",
        "colab_type": "code",
        "outputId": "18bbd736-2e5e-4b16-9a63-25e8d8cf5a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "source": [
        "seq_len = 50\n",
        "bert_model = load_trained_model_from_checkpoint(config_file=paths.config, checkpoint_file=paths.checkpoint, seq_len=seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XB58fvXgkw8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pool_layer = MaskedGlobalMaxPool1D(name='Pooling')(bert_model.output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28JBXhw4k08B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = keras.models.Model(inputs=bert_model.inputs, outputs=pool_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Tcy8LDk0_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_dict = load_vocabulary(paths.vocab)\n",
        "tokenizer = Tokenizer(token_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqsqE6Fhk2yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_bert_vector(doc, bert_model, token_dict, seq_len):\n",
        "    tokenized_doc = tokenizer.tokenize(doc)[:seq_len]\n",
        "    segments = [0] * seq_len\n",
        "    indices = [token_dict[elem] for elem in tokenized_doc]\n",
        "    indices += [0] * (seq_len - len(indices))\n",
        "    return bert_model.predict([np.array([indices]), np.array([segments])])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2TW3J7VpIuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hsvYEjAiCSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/models/all_pairs.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwbuJ2laiWan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = [re.sub('\\s+', ' ', re.sub('(?:[^ ])\\d+', ' ', sent)).strip() for sent in text.split('\\n') if sent.strip()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaKu9vickcU3",
        "colab_type": "code",
        "outputId": "9b5b9936-e5ca-419e-96cd-f11de2ed2a07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(sents)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "363516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gdsgeTqSplR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('all_sents.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(sents))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa-UYOkIjyMi",
        "colab_type": "code",
        "outputId": "0fad53ba-c66b-4f8a-87d2-98d29420d18f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bert_vector_size = 768\n",
        "bert_vectors = np.zeros((len(sents), bert_vector_size))\n",
        "\n",
        "for i, sent in enumerate(sents):\n",
        "    if i % 1000 == 0:\n",
        "        print(i)\n",
        "    bert_vectors[i] = get_bert_vector(sent, bert_model, token_dict, seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "50000\n",
            "51000\n",
            "52000\n",
            "53000\n",
            "54000\n",
            "55000\n",
            "56000\n",
            "57000\n",
            "58000\n",
            "59000\n",
            "60000\n",
            "61000\n",
            "62000\n",
            "63000\n",
            "64000\n",
            "65000\n",
            "66000\n",
            "67000\n",
            "68000\n",
            "69000\n",
            "70000\n",
            "71000\n",
            "72000\n",
            "73000\n",
            "74000\n",
            "75000\n",
            "76000\n",
            "77000\n",
            "78000\n",
            "79000\n",
            "80000\n",
            "81000\n",
            "82000\n",
            "83000\n",
            "84000\n",
            "85000\n",
            "86000\n",
            "87000\n",
            "88000\n",
            "89000\n",
            "90000\n",
            "91000\n",
            "92000\n",
            "93000\n",
            "94000\n",
            "95000\n",
            "96000\n",
            "97000\n",
            "98000\n",
            "99000\n",
            "100000\n",
            "101000\n",
            "102000\n",
            "103000\n",
            "104000\n",
            "105000\n",
            "106000\n",
            "107000\n",
            "108000\n",
            "109000\n",
            "110000\n",
            "111000\n",
            "112000\n",
            "113000\n",
            "114000\n",
            "115000\n",
            "116000\n",
            "117000\n",
            "118000\n",
            "119000\n",
            "120000\n",
            "121000\n",
            "122000\n",
            "123000\n",
            "124000\n",
            "125000\n",
            "126000\n",
            "127000\n",
            "128000\n",
            "129000\n",
            "130000\n",
            "131000\n",
            "132000\n",
            "133000\n",
            "134000\n",
            "135000\n",
            "136000\n",
            "137000\n",
            "138000\n",
            "139000\n",
            "140000\n",
            "141000\n",
            "142000\n",
            "143000\n",
            "144000\n",
            "145000\n",
            "146000\n",
            "147000\n",
            "148000\n",
            "149000\n",
            "150000\n",
            "151000\n",
            "152000\n",
            "153000\n",
            "154000\n",
            "155000\n",
            "156000\n",
            "157000\n",
            "158000\n",
            "159000\n",
            "160000\n",
            "161000\n",
            "162000\n",
            "163000\n",
            "164000\n",
            "165000\n",
            "166000\n",
            "167000\n",
            "168000\n",
            "169000\n",
            "170000\n",
            "171000\n",
            "172000\n",
            "173000\n",
            "174000\n",
            "175000\n",
            "176000\n",
            "177000\n",
            "178000\n",
            "179000\n",
            "180000\n",
            "181000\n",
            "182000\n",
            "183000\n",
            "184000\n",
            "185000\n",
            "186000\n",
            "187000\n",
            "188000\n",
            "189000\n",
            "190000\n",
            "191000\n",
            "192000\n",
            "193000\n",
            "194000\n",
            "195000\n",
            "196000\n",
            "197000\n",
            "198000\n",
            "199000\n",
            "200000\n",
            "201000\n",
            "202000\n",
            "203000\n",
            "204000\n",
            "205000\n",
            "206000\n",
            "207000\n",
            "208000\n",
            "209000\n",
            "210000\n",
            "211000\n",
            "212000\n",
            "213000\n",
            "214000\n",
            "215000\n",
            "216000\n",
            "217000\n",
            "218000\n",
            "219000\n",
            "220000\n",
            "221000\n",
            "222000\n",
            "223000\n",
            "224000\n",
            "225000\n",
            "226000\n",
            "227000\n",
            "228000\n",
            "229000\n",
            "230000\n",
            "231000\n",
            "232000\n",
            "233000\n",
            "234000\n",
            "235000\n",
            "236000\n",
            "237000\n",
            "238000\n",
            "239000\n",
            "240000\n",
            "241000\n",
            "242000\n",
            "243000\n",
            "244000\n",
            "245000\n",
            "246000\n",
            "247000\n",
            "248000\n",
            "249000\n",
            "250000\n",
            "251000\n",
            "252000\n",
            "253000\n",
            "254000\n",
            "255000\n",
            "256000\n",
            "257000\n",
            "258000\n",
            "259000\n",
            "260000\n",
            "261000\n",
            "262000\n",
            "263000\n",
            "264000\n",
            "265000\n",
            "266000\n",
            "267000\n",
            "268000\n",
            "269000\n",
            "270000\n",
            "271000\n",
            "272000\n",
            "273000\n",
            "274000\n",
            "275000\n",
            "276000\n",
            "277000\n",
            "278000\n",
            "279000\n",
            "280000\n",
            "281000\n",
            "282000\n",
            "283000\n",
            "284000\n",
            "285000\n",
            "286000\n",
            "287000\n",
            "288000\n",
            "289000\n",
            "290000\n",
            "291000\n",
            "292000\n",
            "293000\n",
            "294000\n",
            "295000\n",
            "296000\n",
            "297000\n",
            "298000\n",
            "299000\n",
            "300000\n",
            "301000\n",
            "302000\n",
            "303000\n",
            "304000\n",
            "305000\n",
            "306000\n",
            "307000\n",
            "308000\n",
            "309000\n",
            "310000\n",
            "311000\n",
            "312000\n",
            "313000\n",
            "314000\n",
            "315000\n",
            "316000\n",
            "317000\n",
            "318000\n",
            "319000\n",
            "320000\n",
            "321000\n",
            "322000\n",
            "323000\n",
            "324000\n",
            "325000\n",
            "326000\n",
            "327000\n",
            "328000\n",
            "329000\n",
            "330000\n",
            "331000\n",
            "332000\n",
            "333000\n",
            "334000\n",
            "335000\n",
            "336000\n",
            "337000\n",
            "338000\n",
            "339000\n",
            "340000\n",
            "341000\n",
            "342000\n",
            "343000\n",
            "344000\n",
            "345000\n",
            "346000\n",
            "347000\n",
            "348000\n",
            "349000\n",
            "350000\n",
            "351000\n",
            "352000\n",
            "353000\n",
            "354000\n",
            "355000\n",
            "356000\n",
            "357000\n",
            "358000\n",
            "359000\n",
            "360000\n",
            "361000\n",
            "362000\n",
            "363000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek2kDX_oPPrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_most_probable_docs(doc_vector, docs_matrix):\n",
        "    cosine_values = cosine_similarity(docs_matrix, doc_vector.reshape(1, -1)).reshape(docs_matrix.shape[0])\n",
        "    return [sents[sent_id] for sent_id, _ in sorted(list(\n",
        "        enumerate(cosine_values)), key=lambda elem: elem[1], reverse=True)][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTxDoeWRjedv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_bert(query, bert_vectors, bert_model, token_dict, seq_len):\n",
        "    bert_vector = get_bert_vector(query, bert_model, token_dict, seq_len)\n",
        "    return get_most_probable_docs(bert_vector, bert_vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf0jDrNTQqen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bZXDib0P-Fw",
        "colab_type": "code",
        "outputId": "254c95ac-52d3-4374-d0e2-097110d65b12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(bert_vectors.shape, type(bert_vectors))\n",
        "h5f = h5py.File('/content/drive/My Drive/models/bert.h5', 'w')\n",
        "h5f.create_dataset('dataset_1', data=bert_vectors)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363516, 768) <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zX85iYoRL6B",
        "colab_type": "code",
        "outputId": "c59dc51b-c915-45ef-ca0b-e730be5ffd14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "h5f = h5py.File('/content/drive/My Drive/models/bert.h5','r')\n",
        "b = h5f['dataset_1'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTu0tqGfYqRb",
        "colab_type": "code",
        "outputId": "2991e789-aa7c-4af7-a34a-2b98e0f83c34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls /content/drive/My\\ Drive/models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "all_pairs.gdoc\tall_revised_toms.txt  bert.h5\n",
            "all_pairs.txt\tall_sents.txt\t      model.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx2rH1hdO3xH",
        "colab_type": "code",
        "outputId": "eef786a2-b0eb-4533-f8c0-719fd1ab6567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "search_bert('Мне страшно жить здесь', bert_vectors, bert_model, token_dict, seq_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Мне ужасно хотелось спать.',\n",
              " 'И мне страшно.',\n",
              " 'Мне жить хорошо.',\n",
              " 'Мне тяжело.',\n",
              " 'Мне так страшно!',\n",
              " 'Мне жаль.',\n",
              " 'Мне всё хочется плакать.',\n",
              " 'Всегда страшно отпускать.',\n",
              " 'А мне страшно.',\n",
              " 'Тогда легко жить.',\n",
              " 'Только мне ужасно хочется.',\n",
              " 'Мне хочется взглянуть.',\n",
              " 'Мне страшно за вас.',\n",
              " 'А жить мне хорошо.',\n",
              " 'Ему хочется написать.',\n",
              " 'Так мне хорошо одному дома.',\n",
              " 'И мне больно писать.',\n",
              " 'Мне это ужасно нужно.',\n",
              " 'Мне слишком тяжело.',\n",
              " 'Мне надо показаться там.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-k9aSrjk20I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_vector_size = 768\n",
        "bert_vectors = np.zeros((3, bert_vector_size))\n",
        "\n",
        "# for i, tokenized_doc in enumerate(tokenized_docs):\n",
        "\n",
        "bert_vectors[0] = get_bert_vector('Вчера поправлял коректуру об искусстве3 и всю перемарал (Урусов достал сына дьякона, кот орый сейчас переписывает), и в лесу рубил и пилил с мужиками, работающими там.', bert_model, token_dict, seq_len)\n",
        "bert_vectors[1] = get_bert_vector('Дневники же, если я не успею более точно и ясно выразить то, что я записываю в них, могут иметь некоторое значение, хотя бы в тех отрывочных мыслях, которые изложены там.', bert_model, token_dict, seq_len)\n",
        "bert_vectors[2] = get_bert_vector('А каждый день свое приносит омрачение.', bert_model, token_dict, seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afrYyFNymAL5",
        "colab_type": "code",
        "outputId": "558568bf-eebe-4849-86f0-a32b76cf6d5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(cosine_similarity(bert_vectors[0].reshape(1, -1), bert_vectors[1].reshape(1, -1)))\n",
        "print(cosine_similarity(bert_vectors[0].reshape(1, -1), bert_vectors[2].reshape(1, -1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9324744]]\n",
            "[[0.87604891]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C-d-UPuq6qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfTp9ZC9deq",
        "colab_type": "text"
      },
      "source": [
        "Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVIe1K7Zq6uT",
        "colab_type": "code",
        "outputId": "e8199e97-9c27-4908-a1c5-f3f92853e981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "import gensim\n",
        "!pip install pymystem3==0.1.10\n",
        "from pymystem3 import Mystem\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymystem3==0.1.10 in /usr/local/lib/python3.6/dist-packages (0.1.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pymystem3==0.1.10) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pymystem3==0.1.10) (2019.9.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDlr-xegBzMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = Mystem()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCKOHnZwCA1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = 'Мама мыла раму'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxBVpWBpuBmV",
        "colab_type": "code",
        "outputId": "0a5e01aa-5d9a-428f-d915-f99f4f6324c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model_url = 'http://vectors.nlpl.eu/repository/11/180.zip'\n",
        "m = wget.download(model_url)\n",
        "model_file = model_url.split('/')[-1]\n",
        "with zipfile.ZipFile(model_file, 'r') as archive:\n",
        "    stream = archive.open('model.bin')\n",
        "    model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hae-tjP38yw_",
        "colab_type": "code",
        "outputId": "3a49772e-755b-439a-cd8e-4167e5acc37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "model.most_similar(positive=['хуйня_NOUN'], topn=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('фигня_NOUN', 0.5566369891166687),\n",
              " ('пиздец_NOUN', 0.5434011816978455),\n",
              " ('сраный_ADJ', 0.5090421438217163),\n",
              " ('херня_NOUN', 0.5032066106796265),\n",
              " ('черт-те_VERB', 0.4990184009075165),\n",
              " ('ерунда_NOUN', 0.49403128027915955),\n",
              " ('чушь_NOUN', 0.49284014105796814),\n",
              " ('пиздить_VERB', 0.49275171756744385),\n",
              " ('хрень_NOUN', 0.4916004240512848),\n",
              " ('чушь_VERB', 0.4886845350265503),\n",
              " ('блин_PROPN', 0.4870203137397766),\n",
              " ('хули_VERB', 0.4810410737991333),\n",
              " ('мудак_ADV', 0.4789344370365143),\n",
              " ('хер_NOUN', 0.4771116375923157),\n",
              " ('хуе_ADJ', 0.4762328267097473),\n",
              " ('дебил_NOUN', 0.47076573967933655),\n",
              " ('хреновина_NOUN', 0.4682707190513611),\n",
              " ('фуфло_NOUN', 0.4656623601913452),\n",
              " ('балда_NOUN', 0.46197065711021423),\n",
              " ('гроттерша_PROPN', 0.4600300192832947)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrQ3yB_19Diw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}